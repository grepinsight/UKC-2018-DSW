Intermediate R
========================================================
author: Albert Lee, Stephen Park
date: August 3-4, 2018
autosize: true


<style>
.small-code pre code {
  font-size: 1em;
}
</style>

Agenda
========================================================
1. Problem Statement
2. Visualization
3. Machine Learning with Caret
4. K-means Clustering in R

```{r echo=FALSE}
library(caret)
library(tidyverse)
library(useful)
library(cluster)
knitr::opts_chunk$set(echo = TRUE, fig.align="center") # center the figure
```

Motivation
========================================================

Here is the famous `iris` dataset.

![](assets/iris-machinelearning.png)

source: Fisher,R.A. "The use of multiple measurements in taxonomic problems" (see [here](http://archive.ics.uci.edu/ml/datasets/Iris) for more info)

Exercise 1
==============

Open ./exercises/intermediate/exercise1.Rmd and let's expore iris dataset togeother.

Visualization with ggplot2
===========================

- Works with dataframes and not individual vectors

- Consistent underlying `grammar of graphics`

- Can continuously add layers (and themes) to an existing plot

ggplot2 - (1) The Basics
===========================

* Try running this 

```{r}
ggplot(data=iris) 
```

Q: Why is nothing shown?

ggplot2 - (1) The Basics
===========================

```{r}
ggplot(data=iris, mapping=aes(x=Sepal.Width))  
```

* if only X-axis is known. The Y-axis can be specified as well.

ggplot2 - (1) Basics
===========================

```{r}
ggplot(iris, aes(x=Sepal.Width, y=Sepal.Length))
```

* if both X and Y axes are fixed for all layers.

ggplot2 - (1) Basics
===========================
```{r}
ggplot(data=iris, aes(x=Sepal.Width, color=Species))  
# Each category of the 'Species' variable will now have a distinct  color, once a geom is added.
```

ggplot2 - (2) Layers
===========================
class: small-code

```{r }
ggplot(iris, aes(x=Sepal.Width, y=Sepal.Length, color=Species)) + 
  geom_point() + 
  geom_smooth() # Adding scatterplot geom (layer1) and smoothing geom (layer2).
```

ggplot2 - (2) Layers
===========================
class: small-code
```{r}
ggplot(iris) + 
  geom_point(aes(x=Sepal.Width, y=Sepal.Length, shape=Species)) + 
  geom_smooth(aes(x=Sepal.Width, y=Sepal.Length, color=Species)) # Same as above but specifying the aesthetics inside the geoms.
```

ggplot2 - (3)  Labels
===========================
class: small-code

```{r}
gg <- ggplot(iris, aes(x=Sepal.Width, y=Sepal.Length, color=Species)) + 
  geom_point() + 
  labs(title="Scatterplot", x="Sepal Width", y="Sepal Length")  # add axis lables and plot title.
gg
```

ggplot2 - (4) The Facets
===========================
class: small-code

```{r}
gg + 
  facet_wrap( ~ Species, ncol=3)  # columns defined by 'Species'
```

Numerous Possibilites in ggplot2...
===================================
class: small-code

```{r}
ggplot(mtcars, aes(x=cyl)) + geom_bar(fill='darkgoldenrod2') +
  theme(panel.background = element_rect(fill = 'steelblue')) + 
  theme(panel.grid.major = element_line(colour = "firebrick", size=3)) + 
  theme(panel.grid.minor = element_line(colour = "blue", size=1))
```

ggplot2 Documentation
===================================

[Link](https://github.com/rstudio/cheatsheets/raw/master/data-visualization-2.1.pdf)

```{r fig.width=10, fig.height=8,echo=FALSE}
library(png)
library(grid)
img <- readPNG("assets/ggplot2-cheatsheet.png")
grid.raster(img)

```

Here's an interesting machine learning problem
==============================================
class:small-code

__Question: can we guess the type of species based on 4 features?__

```{r echo=FALSE}
iris %>%
  group_by(Species) %>%
  sample_n(3) %>%
  ungroup() %>%
  mutate(Species="???")
```

There are more than one ways to solve this problem, but we will use a particular way to do this....

Machine Learning Workflow
=========================


![](assets/machine_learning_workflow.png)

1. Why do we split a data into train/test datasets?

Supervised vs. Unsupervised Learning
=======================================
```{r echo=FALSE, out.width = "1400px"}
knitr::include_graphics("assets/Supervised-Unsupervised.jpg")
```

What is caret?
==============

* It stands for  __C__lassification __A__nd __RE__gression __T__raining
* Machine learning framework in R
* Learn one workflow, leverage +100 models
* http://caret.r-forge.r-project.org/

```{r}
# type `help(package = "caret")` for more info
```

Caret consists of 4 steps
=========================

1. Partition data into train / test data
1. Model Selection and Parameter tuning
1. Prediction
1. Performance check


Training/Test Split
===================

```{r}
set.seed(123)
idx_train <- caret::createDataPartition(
  y = iris$Species,
  p = .75,
  list = FALSE
)
```

1. What does `set.seed(123)` do?
2. Read the documentation of `caret::createDataPartition`
3. what does `p=0.75` mean?
4. can you `str(idx_train)` to see its structure?

Training/Test Split
===================

```{r}
str(idx_train)
class(idx_train)
```


Training/Test Split
===================
```{r}
head(idx_train)
```

Training/Test Split Cont
===================
```{r}
data_all <- iris
data_training <- data_all[idx_train, ]
data_test <- data_all[-idx_train, ]
```

1. what am I doing here?
2. what does `-idx_train` mean?
3. can you run `dim` commands on each of the dataset?

```{r eval=FALSE}
dim(data_all)
dim(data_training)
dim(data_test)
```

Model Building
===================

1. will build a train control


```{r}
# build train control
ctrl <- caret::trainControl(
  method = "cv",
  number = 10,
  classProbs = TRUE,
  summaryFunction = caret::mnLogLoss
)
```

1. type `ctrl` on your console. What is the data structure?

```{r eval=FALSE}
ctrl
str(ctrl)
class(ctrl)
```

Model Building
===================

```{r}
model <- caret::train(
  x = data_training[,1:4],
  y = data_training$Species,
  trControl = ctrl,
  method = "rf",
  verbose=TRUE
)
```


1. what is `rf`?
2. what is `preProc`?
3. what is `metric`?

Model Building
===================

```{r}
ggplot(model)
```


Prediction
==========
```{r}
data_pred_class <- predict(model, newdata=data_test, type="raw")
data_pred_prob <- predict(model, newdata=data_test, type="prob")
```

Prediction
==========

```{r eval=FALSE}
confusionMatrix(data = data_pred_class, data_test$Species)
```

1. what is the sensitivity?
2. what is the accuracy?


Variable Importance
====================

```{r eval=FALSE}
caret::varImp(model)
```

1. What variables are important?
2. Can you confirm this with a plot?

Variable Importance
====================

```{r}
ggplot(iris, aes(x=Petal.Width, fill=Species)) + 
  geom_density() + 
  theme_bw()
```


More sophisticated version
==========================

```{r}
model_v2 <- caret::train(
  x = data_training[,1:4],
  y = data_training$Species,
  trControl = ctrl,
  method = "rf",
  ## Center and scale the predictors for the training
  ## set and all future samples.
  preProc = c("center", "scale"),
  metric="logLoss"
)
```


Tips
====

```{r}
info_caret_models  <- caret::getModelInfo()
names(info_caret_models)
info_caret_models$rf$parameters
```


Regression
===========
```{r}
ctrl <- caret::trainControl(method="cv", number = 10)
model_linear <- caret::train(x = data_training[,1:3], 
             y = data_training$Petal.Width, 
             method = "lm", 
             trControl = ctrl,
             metric="RMSE")
caret::RMSE(predict(model_linear, newdata=data_test), data_test$Petal.Width)
```

Unsupervised Machine Learning: Clustering
=========================================
```{r echo=FALSE, out.width = "1400px"}
knitr::include_graphics("assets/kmeans.jpg")
```

K-means Clustering of the Iris Data
========================================================
```{r}
set.seed(278613)
iris_without_class <- iris[, which(names(iris) != "Species")]
results <- kmeans(x = iris_without_class, centers = 3)
head(results, n=2)
```

Base Scatterplots for the Petals
========================================================

```{r, fig.height=10, fig.width=19}
par(mfrow=c(1,2), bty="n", cex=2)
plot(iris[c("Petal.Length", "Petal.Width")], col=results$cluster)
plot(iris[c("Petal.Length", "Petal.Width")], col=iris$Species)
```


Base Scatterplots for the Sepals
========================================================

```{r, fig.height=10, fig.width=19}
par(mfrow=c(1,2), bty="n", cex=2)
plot(iris[c("Sepal.Length", "Sepal.Width")], col=results$cluster)
plot(iris[c("Sepal.Length", "Sepal.Width")], col=iris$Species)
```

Analyzing the Clustering Results
========================================================

```{r}
table(iris$Species, results$cluster)
```

1. Which Iris plant is linearly separable from the other?

3. Does the results of the K-means clustering show “the data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant”?

Fit Assessment of K-means Clustering
========================================================

```{r}
plot(table(iris$Species, results$cluster), main="Confustion Matrix for Iris Clustering", "xlab=Cultivar", ylab="Cluster")
```

Choosing the Right Number of Clusters: Hartigan's Rule
========================================================
```{r, fig.height=5, fig.width=10}
irisBest <- FitKMeans(iris_without_class, max.clusters=20, nstart=25)
PlotHartigan(irisBest)
```

Another Method: the Gap Statistic
========================================================
```{r, fig.height=5, fig.width=10}
theGap <- clusGap(iris_without_class, FUNcluster=pam, K.max=20)
gapDF <- as.data.frame(theGap$Tab)
ggplot(gapDF, aes(x=1:nrow(gapDF))) + geom_line(aes(y=gap))
```

Futher studies
==============

1. [Caret Documentation](https://topepo.github.io/caret/index.html)
2. [R for Data Science](http://r4ds.had.co.nz/)
